{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Assignment#2_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherylsqin/CE888/blob/master/Assignment2/Assignment_2_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pv5OTw04WD3",
        "colab_type": "code",
        "outputId": "a58f7bad-3755-436a-8ae1-e5ba9118300d",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt #plotting charts\n",
        "import pandas as pd #helps importing datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "from math import *\n",
        "import random\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprt-aH94WD6",
        "colab_type": "text"
      },
      "source": [
        "__QUESTION 2__\n",
        "\n",
        "As from out previous dataset generated from assignment 1 a function decision_tree_classifier() function implemented to train \n",
        "the decision tree and return the classifier. \n",
        "\n",
        "The input data set is split into 60 for train set and 40 percent for test set. A graph is plotted between accuracy and depth of the tree for 50 iterations. The highest accuracy from the depth of the tree will used to train the DT classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q7_old34WD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decision_tree_classifier(input_dat, get_depth, depth_max):\n",
        "    #Split data into 60-40 percent for training and testing\n",
        "    #print(len(input_dat))\n",
        "    train_set, test_set = train_test_split(input_dat, test_size = 0.4, random_state = 55)\n",
        "    \n",
        "    #Select from column 1-9 for training set (oxo board position)\n",
        "    train_x = train_set.iloc[:,0:9]\n",
        "    #Select column best move of each stage for training set\n",
        "    train_y = train_set.iloc[:,-1]\n",
        "    train_y = train_y.astype('int')\n",
        "    \n",
        "    #Select from column 1-9 for test set (oxo board position)\n",
        "    test_x = test_set.iloc[:,0:9]\n",
        "    #Select column best move of each stage for test set\n",
        "    test_y = test_set.iloc[:,-1]\n",
        "    test_y = test_y.astype('int')\n",
        "    \n",
        "    #Plotting data accuracy vs tree's depth from 0 to 49\n",
        "    if(get_depth == 1):\n",
        "        #print(\"in if get_depth==1 : \", get_depth)\n",
        "        depth_range = list(range(1,50))\n",
        "        accuracy_list = []\n",
        "        for depth in depth_range:\n",
        "            dt_classifier_1 = DecisionTreeClassifier(criterion='gini',max_depth=depth,random_state=55)\n",
        "            dt_classifier_1.fit(train_x, train_y)\n",
        "            score = dt_classifier_1.score(test_x, test_y)\n",
        "            accuracy_list.append(score)\n",
        "        plt.plot(depth_range,accuracy_list, label = 'Accuracy')\n",
        "        plt.legend(framealpha = 1, frameon = True)\n",
        "        plt.xlabel('Tree Depth')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.show()  \n",
        "        #Select the maximum accuracy with the first run and train the classifier again on the same depth\n",
        "        depth_max = (accuracy_list.index(max(accuracy_list)) + 1)\n",
        "        print(\"Maximum accuracy : \", max(accuracy_list))\n",
        "        print(\"Maximum depth of decision tree is : \", depth_max)\n",
        "    \n",
        "    #Train the classifier with the maximum accuracy in every iterations\n",
        "    dt_classifier = DecisionTreeClassifier(criterion='gini',max_depth=depth_max,random_state=55)\n",
        "    dt_classifier.fit(train_x, train_y)\n",
        "    pred_test_y = dt_classifier.predict(test_x)\n",
        "    \n",
        "    #Print confusion matrix in order to see the precision/recall/accuracy\n",
        "    print(classification_report(test_y,pred_test_y)) \n",
        "    \n",
        "    #Export decision tree graphic\n",
        "    dot_data = StringIO()\n",
        "    export_graphviz(dt_classifier, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True)\n",
        "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "    graph.write_png('decision_tree.png')\n",
        "    Image(graph.create_png())\n",
        "\n",
        "    return dt_classifier, depth_max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf04KGCW4WD9",
        "colab_type": "text"
      },
      "source": [
        "__QUESTION 4__\n",
        "\n",
        "This function is made to satisfy the flip coin condition.\n",
        "\n",
        "def GetRandomMove(state, clf):\n",
        "    \n",
        "Random method uniform, so we can set up the lowerbound and upperbound in order to match with Question 4 where we need to do 90% with best move by DT and 10% by random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo1JApIn4WD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OXOState:\n",
        "    \"\"\" A state of the game, i.e. the game board.\n",
        "        Squares in the board are in this arrangement\n",
        "        012\n",
        "        345\n",
        "        678\n",
        "        where 0 = empty, 1 = player 1 (X), 2 = player 2 (O)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.playerJustMoved = 2 \n",
        "        # At the root pretend the player just moved is 2 whereas player 1 has the first move.\n",
        "        self.board = [0,0,0,0,0,0,0,0,0] \n",
        "        # 0 = empty, 1 = player 1, 2 = player 2. This is the initial board state - all positions are empty.\n",
        "        \n",
        "    def Clone(self):\n",
        "        \"\"\" Create a deep clone of this game state.\n",
        "        \"\"\"\n",
        "        st = OXOState()\n",
        "        st.playerJustMoved = self.playerJustMoved\n",
        "        st.board = self.board[:]\n",
        "        return st\n",
        "\n",
        "    def DoMove(self, move):\n",
        "        \"\"\" Update the state board by replacing 0 with the player playing the move at the position/move of the board.\n",
        "            Must update playerJustMoved.\n",
        "        \"\"\"\n",
        "        assert move >= 0 and move <= 8 and move == int(move) and self.board[move] == 0\n",
        "        self.playerJustMoved = 3 - self.playerJustMoved\n",
        "        self.board[move] = self.playerJustMoved\n",
        "        \n",
        "    def GetMoves(self):\n",
        "        \"\"\" Get all possible moves from this state. That is return all the positional values of the zroes in the state board.\n",
        "        \"\"\"\n",
        "        return [i for i in range(9) if self.board[i] == 0]\n",
        "    \n",
        "    def GetResult(self, playerjm):\n",
        "        \"\"\" Get the game result from the viewpoint of playerjm. \n",
        "        \"\"\"\n",
        "        for (x,y,z) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]:\n",
        "            #Winning possibilities of the board\n",
        "            if self.board[x] == self.board[y] == self.board[z]: \n",
        "                # check if values in all the 3 positions is of the same player\n",
        "                # check if the player that just moved is same as the value in the winning positions, \n",
        "                #if yes return 1 else 0 stating that the other player wins.\n",
        "                if self.board[x] == playerjm: \n",
        "                    return 1.0\n",
        "                else:\n",
        "                    return 0.0\n",
        "        if self.GetMoves() == []:\n",
        "            return 0.5 # draw\n",
        "        return False # Should not be possible to get here\n",
        "\n",
        "    def __repr__(self): # This is how the return value is defined for this class.\n",
        "        s= \"\"\n",
        "        for i in range(9): \n",
        "            s += \".XO\"[self.board[i]] # . for 0, X for 1 and O for 2 positional values\n",
        "            if i % 3 == 2: s += \"\\n\"\n",
        "        return s\n",
        "\n",
        "class Node:\n",
        "    \"\"\" A node in the game tree. Note : wins is always from the viewpoint of playerJustMoved.\n",
        "        Crashes if state not specified.\n",
        "    \"\"\"\n",
        "    def __init__(self, move = None, parent = None, state = None):\n",
        "        self.move = move # the move that got us to this node - \"None\" for the root node\n",
        "        #parentNode stores all the parents from the rootnode until the current \n",
        "        #node for backpropogation, during which it deletes until it is None.\n",
        "        self.parentNode = parent # \"None\" for the root node.\n",
        "        self.childNodes = []\n",
        "        self.wins = 0\n",
        "        self.visits = 0 #The number of itermax passed\n",
        "        self.untriedMoves = state.GetMoves() \n",
        "        # future child nodes. The available positions to be played at any point of the game.\n",
        "        self.playerJustMoved = state.playerJustMoved \n",
        "        # the only part of the state that the Node needs later\n",
        "        \n",
        "    def UCTSelectChild(self):\n",
        "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
        "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
        "            exploration versus exploitation.\n",
        "        \"\"\"\n",
        "        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1] \n",
        "        #pick the highest\n",
        "        return s\n",
        "    \n",
        "    def AddChild(self, m, s):\n",
        "        \"\"\" Remove m from untriedMoves and add a new child node for this move.\n",
        "            Return the added child node.\n",
        "        \"\"\"\n",
        "        n = Node(move = m, parent = self, state = s)\n",
        "        self.untriedMoves.remove(m)\n",
        "        self.childNodes.append(n)\n",
        "        return n\n",
        "    \n",
        "    def Update(self, result):\n",
        "        \"\"\" Update this node - one additional visit and result additional wins. result must be \n",
        "        from the viewpoint of playerJustmoved.\n",
        "        \"\"\"\n",
        "        self.visits += 1\n",
        "        self.wins += result\n",
        "\n",
        "    def __repr__(self): # Added other variables to be returned to check the flow \n",
        "        #of the variable during testing small iterations.\n",
        "        return \"[M:\" + str(self.move) + \" W/V:\" + str(self.wins) + \"/\" + str(self.visits) + \" U:\" + str(self.untriedMoves) + \" PJM:\" + str(self.playerJustMoved) + \"]\"\n",
        "\n",
        "    def TreeToString(self, indent):\n",
        "        s = self.IndentString(indent) + str(self)\n",
        "        for c in self.childNodes:\n",
        "             s += c.TreeToString(indent+1)\n",
        "        return s\n",
        "\n",
        "    def IndentString(self,indent):\n",
        "        s = \"\\n\"\n",
        "        for i in range (1,indent+1):\n",
        "            s += \"| \"\n",
        "        return s\n",
        "\n",
        "    def ChildrenToString(self):\n",
        "        s = \"\"\n",
        "        for c in self.childNodes:\n",
        "             s += str(c) + \"\\n\"\n",
        "        return s\n",
        "\n",
        "def GetRandomMove(state, clf):\n",
        "    \n",
        "    #Random method uniform, so we can set up the lowerbound and upperbound in order\n",
        "    #to match with Question 4 where we need to do 90% with best move by DT and 10% by random\n",
        "    rng_num = random.uniform(0.0, 1.0)\n",
        "\n",
        "    if rng_num <= 0.9:\n",
        "        next_move=clf.predict([state.board])\n",
        "        next_move=next_move[0]\n",
        "    \n",
        "        #If moved decided by DT is not in untried moves, we will generate next move randomly\n",
        "        if next_move not in state.GetMoves():\n",
        "            next_move=random.choice(state.GetMoves())\n",
        "            #Update the move position to global variable 'record_state'.\n",
        "            #A combined stage where we used this data to traind for the next train\n",
        "            \n",
        "            state_board=list(state.board) #Store the position state \n",
        "            state_board.append(next_move) \n",
        "            record_state.append(state_board) #update to record_state       \n",
        "    else:\n",
        "        next_move=random.choice(state.GetMoves())\n",
        "    return next_move\n",
        "    \n",
        "def UCT(initiate_run, clf, rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "    Return the best move from the rootstate.\n",
        "    Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)\n",
        "            m = random.choice(node.untriedMoves) # this m has to be picked by the DT train 90% times and 10% randomly.\n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m, state)  # add child and descend tree. This updates the parent node as well.\n",
        "\n",
        "        # Rollout\n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "            #if initiate_run == 1: # if the code is executed from the scratch and no initial input file of states is given.\n",
        "                #r = random.choice(state.GetMoves())\n",
        "            #else:\n",
        "            r = GetRandomMove(state, clf)\n",
        "            state.DoMove(r)\n",
        "        \n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            gr=state.GetResult(node.playerJustMoved)\n",
        "            node.Update(gr) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move\n",
        "                \n",
        "def UCTPlayGame(initiate_run, clf): #Monte Carlo Tree Search\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    state = OXOState()\n",
        "    #get_win_state = []\n",
        "    board_xo = [[0,0,0,0,0,0,0,0,0]]\n",
        "    best_move = [] \n",
        "    \n",
        "    while state.GetMoves() != []:  \n",
        "        #print(str(state))\n",
        "        if state.playerJustMoved == 1: \n",
        "            m = UCT(initiate_run, clf, rootstate=state, itermax=100, verbose=False)  \n",
        "        else:\n",
        "            m = UCT(initiate_run, clf, rootstate=state, itermax=100, verbose=False) \n",
        "        \n",
        "        state.DoMove(m)\n",
        "        best_move.append(m)\n",
        "        board_xo.append(list(state.board))\n",
        "        \n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #board_xo.append(state.board)\n",
        "            break\n",
        "    \n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        #print(\"Player \" + str(state.playerJustMoved) + \" wins!\") #Commented to save space for the output\n",
        "        get_winner = state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        #print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\") #Commented to save space for the output\n",
        "        get_winner = (3-state.playerJustMoved)\n",
        "    else: \n",
        "        #print(\"Nobody wins!\") #Commented to save space for the output\n",
        "        get_winner=0\n",
        "\n",
        "    best_move.append('NA')\n",
        "    \n",
        "    for i in range(len(board_xo)): \n",
        "        board_xo[i].append(best_move[i]) # Append the move taken at every stage.\n",
        "\n",
        "    return board_xo, get_winner \n",
        "\n",
        "def get_oxo_dataset(num_classifier, initiate_run, clf):\n",
        "    \n",
        "    single_dataset = []\n",
        "    all_dataset = [] \n",
        "    \n",
        "    win_p1 = 0\n",
        "    win_p2 = 0\n",
        "    no_one_win = 0\n",
        "    get_winner = 0\n",
        "    \n",
        "    for i in range(num_classifier): \n",
        "      # Run the UCTPlayGame 1000 times.\n",
        "        stage_xo, winner = UCTPlayGame(initiate_run, clf) # returnds stores the game temporarily.\n",
        "       \n",
        "        single_dataset.append(stage_xo) \n",
        "        \n",
        "        if winner == 1:\n",
        "            win_p1 += 1\n",
        "        elif winner == 2:\n",
        "            win_p2 += 1\n",
        "        else:\n",
        "            no_one_win += 1\n",
        "\n",
        "    #Convert list of lists to one list\n",
        "    for i in single_dataset:  \n",
        "        for j in i:  \n",
        "            all_dataset.append(j) \n",
        "\n",
        "    #Name the columns of the finaldataset1 and convert it into a dataframe.\n",
        "    pd_data = pd.DataFrame(all_dataset, columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Move'])\n",
        "     \n",
        "    #Remove the rows that have 'NA' as these are the rows depicting the last stage of the game with no move.\n",
        "    pd_data.drop(pd_data[pd_data.Move == 'NA'].index, inplace=True)\n",
        "    pd_data.reset_index(drop=True, inplace=True) #  Reset the row index of the data frame\n",
        "    \n",
        "    #Output for new no bias dataset\n",
        "    #pd_data.to_csv('output_test1.csv',index=True)\n",
        "    #pd_data.to_csv('doc-' + str(fileCounter) + '.csv', index=False)\n",
        "    #fileCounter += 1\n",
        "\n",
        "    #print(\"Wins : Player1 : \", win_p1, \" Player2 : \", win_p2, \" Nobody wins : \", no_one_win)\n",
        "    \n",
        "    return pd_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qInGAebO4WD_",
        "colab_type": "text"
      },
      "source": [
        "__QUESTION 5__\n",
        "\n",
        "Implement a funtion 'build_dict_classifier', a collection of data from DT classsifier to generate a new unbias dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqkZI4-W4WEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dict_classifier(num_classifier, num_game, have_file, ori_data\n",
        "   get_depth=1\n",
        "   depth_max=0\n",
        "   dict_classifier=dict()\n",
        "   classifier=None\n",
        "   \n",
        "   \"\"\"first_run is a flag depicting if the code is going to create a dataset of 2000 games for the first time or not. \n",
        "      1 means it is a first run and 0 means it is not.\n",
        "   \"\"\"\n",
        "   if (have_file == 1):\n",
        "       classifier, depth_max = decision_tree_classifier(ori_data, get_depth, depth_max)\n",
        "       #print('Max depth : ', depth_max)\n",
        "       dict_classifier[int('0')] = classifier\n",
        "       num_classifier = num_classifier-1\n",
        "       first_run = 0\n",
        "       get_depth = 0\n",
        "   else:\n",
        "       first_run = 1\n",
        "    \n",
        "   for i in range(num_classifier):\n",
        "       #print('Value of i : ', i)\n",
        "       oxo_data=get_oxo_dataset(num_game, first_run, classifier) \n",
        "       \n",
        "       combi_train_state=pd.DataFrame(record_state,columns=['0th pos', '1st pos', '2nd pos', '3rd pos', '4th pos', '5th pos', '6th pos', '7th pos', '8th pos', 'Move'])\n",
        "       #combine the oxo_data and combi_train_state to use in more DT classifier\n",
        "       oxo_data=pd.concat([oxo_data,combi_train_state],ignore_index=True, axis=0)\n",
        "        \n",
        "       #Train data again                   \n",
        "       classifier, depth_max = decision_tree_classifier(oxo_data, get_depth, depth_max)\n",
        "       #print('Maximum depth : ', depth_max)\n",
        "       \n",
        "       if(have_file == 1):\n",
        "           dict_classifier.update({i+1:classifier})\n",
        "       else:\n",
        "           dict_classifier.update({i:classifier})\n",
        "       \n",
        "       first_run=0\n",
        "       get_depth=0\n",
        "       record_state.clear()\n",
        "   #Output for overall unbias game (50 games)\n",
        "   #oxo_data.to_csv('output_test.csv',index=True)\n",
        "   return dict_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCArwv_R4WEC",
        "colab_type": "text"
      },
      "source": [
        "__QUESTION 6__\n",
        "\n",
        "Modify the OXO Game for Classifiers (Reinforcement)\n",
        "\n",
        "We presume here that Player 1 related with every 10th classifier and Player 2 is related with its previous 9 classifier events.\n",
        "\n",
        "For example :\n",
        "\n",
        "10th Decision Tree Classifier will play versus 1st Decision Tree Classifier, 2nd Decision Tree Classifier up until 9th Decision Tree Classifier. Once it completed its round, we will calcualte the number of times the 10th Decision Tree Classifier won against the rest of Decision Tree Classifier (1st-9th).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lplwswR84WED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetRandomMove_mod(DTclassifier, state):\n",
        "    rnd = DTclassifier.predict([state.board])\n",
        "    rnd = rnd[0]\n",
        "    if rnd not in state.GetMoves():\n",
        "        rnd = random.choice(state.GetMoves())\n",
        "    return rnd\n",
        "\n",
        "def UCT_mod(p1_clf, p2_clf,rootstate, itermax, verbose = False):\n",
        "    \"\"\" Conduct a UCT search for itermax iterations starting from rootstate.\n",
        "        Return the best move from the rootstate.\n",
        "        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0].\"\"\"\n",
        "\n",
        "    rootnode = Node(state = rootstate)\n",
        "\n",
        "    for i in range(itermax):\n",
        "        node = rootnode\n",
        "        state = rootstate.Clone()\n",
        "\n",
        "        # Select\n",
        "        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal\n",
        "            node = node.UCTSelectChild()\n",
        "            state.DoMove(node.move)\n",
        "\n",
        "        # Expand\n",
        "        if node.untriedMoves != []:\n",
        "            m = random.choice(node.untriedMoves)\n",
        "            state.DoMove(m)\n",
        "            node = node.AddChild(m,state) # add child and descend tree\n",
        "\n",
        "        # Rollout \n",
        "        while state.GetMoves() != []: # while state is non-terminal\n",
        "\n",
        "            if(state.playerJustMoved==1):\n",
        "                rnd = GetRandomMove_mod(p1_clf,state)\n",
        "            else:\n",
        "                rnd = GetRandomMove_mod(p2_clf,state)\n",
        "            state.DoMove(rnd)\n",
        "\n",
        "        # Backpropagate\n",
        "        while node != None: # backpropagate from the expanded node and work back to the root node\n",
        "            node.Update(state.GetResult(node.playerJustMoved)) # state is terminal. Update node with result from POV of node.playerJustMoved\n",
        "            node = node.parentNode\n",
        "\n",
        "    # Output some information about the tree - Commented to save space for Output\n",
        "    #if (verbose): print(rootnode.TreeToString(0))\n",
        "    #else: print(rootnode.ChildrenToString())\n",
        "\n",
        "    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited\n",
        "                \n",
        "def UCTPlayGame_mod(p1_clf, p2_clf):\n",
        "    \"\"\" Play a sample game between two UCT players where each player gets a different number \n",
        "        of UCT iterations (= simulations = tree nodes).\n",
        "    \"\"\"\n",
        "    \n",
        "    state = OXOState() \n",
        "    \n",
        "    while (state.GetMoves() != []):\n",
        "        #print(str(state)) #Commented to save space for Output\n",
        "        if state.playerJustMoved == 1:\n",
        "            m = UCT_mod(p1_clf, p2_clf, rootstate = state, itermax = 100, verbose = False) \n",
        "        else:\n",
        "            m = UCT_mod(p1_clf, p2_clf, rootstate = state, itermax =100, verbose = False)\n",
        "        #print(\"Best Move: \" + str(m) + \"\\n\") #Commented to save space for Output\n",
        "        state.DoMove(m)\n",
        "        if state.GetResult(state.playerJustMoved) != False:\n",
        "            #print(str(state)) #Commented to save space for Output\n",
        "            break\n",
        "    if state.GetResult(state.playerJustMoved) == 1.0:\n",
        "        #print(\"Player \" + str(state.playerJustMoved) + \" wins!\") #Commented to save space for Output\n",
        "        return state.playerJustMoved\n",
        "    elif state.GetResult(state.playerJustMoved) == 0.0:\n",
        "        #print(\"Player \" + str(3 - state.playerJustMoved) + \" wins!\") #Commented to save space for Output\n",
        "        return (3-state.playerJustMoved)\n",
        "    else:\n",
        "        #print(\"Nobody wins!\") #Commented to save space for Output\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJsqIOTu4WEF",
        "colab_type": "text"
      },
      "source": [
        "__MAIN FUNCTION__\n",
        "\n",
        "Main function calls build_dict_classifier() function to create a dictionary to store set of  of trained classifiers on the previous 1000 games dataset from assignment 1. \n",
        "\n",
        "After we complete a new data from the classifier which store in the dictionary.OXO Game is played between the classifiers by calling UCTPlayGame_mod() function. The UCTPlayGamemod() function is provided with two classifer events , the 1st event is always the 10th classifier and the 2nd events will rnge from from 1st classifier upto  9th classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkAHZk1p4WEG",
        "colab_type": "code",
        "outputId": "dd3d69d7-b18a-4158-d212-9d0da85a2c84",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # create a global list to record the unexpected states encountered by the Decision tree. These are states for which DT could not give an eligible move.\n",
        "    global record_state\n",
        "    record_state = []\n",
        "    have_file = 1\n",
        "    num_game = int(input(\"Please enter the number of games to be played : \"))\n",
        "    num_classifier = int(input('Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : '))\n",
        "  \n",
        "    print('Attempting to import the generated dataset ')\n",
        "    ori_data = pd.read_csv('C:/Users/shery/output_1000_itrerations.csv')\n",
        "    print('Finish importing the dataset')\n",
        "    \n",
        "    collection_classifier = build_dict_classifier(num_classifier, num_game, have_file, ori_data)\n",
        "    #print('Length of dictionary : ', len(collection_classifier))\n",
        "    #print('dictionary : ', collection_classifier)\n",
        "\n",
        "    for i in range(0,len(collection_classifier),10):\n",
        "        dt_10 = 0\n",
        "        other_dt = 0\n",
        "        draw = 0\n",
        "        j=i\n",
        "        for j in range(i, i+9): # execute from 0 until 8th index of every tenth position\n",
        "            #Stage 6 to get the agent play with the past self data\n",
        "            get_winner = UCTPlayGame_mod(collection_classifier[9+10*(i//10)], collection_classifier[j]) \n",
        "            #transfer 9 always and every value from 0 to 8\n",
        "            #print(get_winner)\n",
        "            if get_winner == 1:\n",
        "                print('Decision Tree 10 wins')\n",
        "                dt_10 += 1\n",
        "            elif get_winner == 2:\n",
        "                print('Decesion Tree',i+1,' wins')\n",
        "                other_dt += 1\n",
        "            else:\n",
        "                print('No winning')\n",
        "                draw += 1\n",
        "        print(\"Win Result : \\n 10thDecisionTree  : \", dt_10, \" OtherDecisionTree : \", other_dt, \" Draw : \", draw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter the number of games to be played : 10\n",
            "Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 50\n",
            "Attempting to import the generated dataset \n",
            "Finish importing the dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum accuracy :  0.6877673224978614\n",
            "Maximum depth of decision tree is :  11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.89      0.65       378\n",
            "           1       0.69      0.72      0.71       368\n",
            "           2       0.69      0.58      0.63       422\n",
            "           3       0.74      0.62      0.68       390\n",
            "           4       0.74      0.61      0.67       428\n",
            "           5       0.82      0.76      0.79       394\n",
            "           6       0.60      0.56      0.58       364\n",
            "           7       0.77      0.81      0.79       375\n",
            "           8       0.77      0.65      0.71       388\n",
            "\n",
            "    accuracy                           0.69      3507\n",
            "   macro avg       0.71      0.69      0.69      3507\n",
            "weighted avg       0.71      0.69      0.69      3507\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.45      0.43       254\n",
            "           1       0.45      0.57      0.50      1000\n",
            "           2       0.48      0.51      0.50       762\n",
            "           3       0.50      0.55      0.52       999\n",
            "           4       0.48      0.49      0.49       289\n",
            "           5       0.57      0.50      0.53      1071\n",
            "           6       0.47      0.45      0.46       705\n",
            "           7       0.56      0.51      0.53      1097\n",
            "           8       0.60      0.50      0.54      1208\n",
            "\n",
            "    accuracy                           0.51      7385\n",
            "   macro avg       0.50      0.50      0.50      7385\n",
            "weighted avg       0.52      0.51      0.51      7385\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.80      0.42         5\n",
            "           1       1.00      0.29      0.44         7\n",
            "           2       0.33      0.29      0.31         7\n",
            "           3       0.57      0.40      0.47        10\n",
            "           4       0.13      0.43      0.20         7\n",
            "           5       0.25      0.25      0.25         8\n",
            "           6       0.40      0.18      0.25        11\n",
            "           7       0.39      0.35      0.37        20\n",
            "           8       0.80      0.31      0.44        13\n",
            "\n",
            "    accuracy                           0.34        88\n",
            "   macro avg       0.46      0.37      0.35        88\n",
            "weighted avg       0.48      0.34      0.36        88\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.62      0.57       408\n",
            "           1       0.60      0.68      0.64       928\n",
            "           2       0.55      0.57      0.56       515\n",
            "           3       0.58      0.60      0.59       546\n",
            "           4       0.61      0.58      0.59       323\n",
            "           5       0.50      0.48      0.49       677\n",
            "           6       0.61      0.59      0.60       632\n",
            "           7       0.42      0.28      0.33       229\n",
            "           8       0.64      0.52      0.57       502\n",
            "\n",
            "    accuracy                           0.57      4760\n",
            "   macro avg       0.56      0.55      0.55      4760\n",
            "weighted avg       0.57      0.57      0.57      4760\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.26      0.29        19\n",
            "           1       0.17      0.71      0.27         7\n",
            "           2       0.38      0.29      0.33        17\n",
            "           3       0.18      0.17      0.17        18\n",
            "           4       0.29      0.33      0.31        18\n",
            "           5       0.18      0.10      0.13        20\n",
            "           6       0.33      0.08      0.12        13\n",
            "           7       0.60      0.33      0.43         9\n",
            "           8       0.34      0.41      0.38        29\n",
            "\n",
            "    accuracy                           0.28       150\n",
            "   macro avg       0.31      0.30      0.27       150\n",
            "weighted avg       0.30      0.28      0.27       150\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.68      0.63       320\n",
            "           1       0.54      0.59      0.57       471\n",
            "           2       0.52      0.62      0.57       382\n",
            "           3       0.60      0.57      0.59       185\n",
            "           4       0.60      0.46      0.52       155\n",
            "           5       0.70      0.66      0.68       548\n",
            "           6       0.67      0.58      0.62       458\n",
            "           7       0.64      0.69      0.66       707\n",
            "           8       0.71      0.61      0.66       723\n",
            "\n",
            "    accuracy                           0.63      3949\n",
            "   macro avg       0.62      0.61      0.61      3949\n",
            "weighted avg       0.63      0.63      0.63      3949\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.48      0.40        21\n",
            "           1       0.31      0.36      0.33        45\n",
            "           2       0.25      0.24      0.24        50\n",
            "           3       0.25      0.15      0.19        34\n",
            "           4       0.25      0.15      0.19        26\n",
            "           5       0.17      0.32      0.22        50\n",
            "           6       0.30      0.31      0.31        42\n",
            "           7       0.25      0.22      0.23        78\n",
            "           8       0.12      0.08      0.09        66\n",
            "\n",
            "    accuracy                           0.24       412\n",
            "   macro avg       0.25      0.26      0.25       412\n",
            "weighted avg       0.24      0.24      0.23       412\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62       365\n",
            "           1       0.49      0.61      0.54       386\n",
            "           2       0.68      0.64      0.66       730\n",
            "           3       0.64      0.57      0.61       595\n",
            "           4       0.55      0.54      0.55       178\n",
            "           5       0.63      0.66      0.64       561\n",
            "           6       0.45      0.59      0.51       228\n",
            "           7       0.59      0.51      0.55       424\n",
            "           8       0.63      0.60      0.61       694\n",
            "\n",
            "    accuracy                           0.60      4161\n",
            "   macro avg       0.59      0.60      0.59      4161\n",
            "weighted avg       0.61      0.60      0.60      4161\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.41      0.23        17\n",
            "           1       0.26      0.53      0.35        15\n",
            "           2       0.29      0.20      0.24        30\n",
            "           3       0.32      0.33      0.33        21\n",
            "           4       0.38      0.40      0.39        25\n",
            "           5       0.28      0.31      0.29        36\n",
            "           6       0.34      0.35      0.34        49\n",
            "           7       0.14      0.05      0.07        22\n",
            "           8       0.50      0.04      0.07        26\n",
            "\n",
            "    accuracy                           0.28       241\n",
            "   macro avg       0.30      0.29      0.26       241\n",
            "weighted avg       0.31      0.28      0.26       241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.51      0.50       205\n",
            "           1       0.49      0.55      0.52       234\n",
            "           2       0.63      0.75      0.68       454\n",
            "           3       0.58      0.55      0.57       325\n",
            "           4       0.42      0.44      0.43        95\n",
            "           5       0.71      0.64      0.68       466\n",
            "           6       0.61      0.51      0.56       239\n",
            "           7       0.69      0.67      0.68       728\n",
            "           8       0.74      0.74      0.74       831\n",
            "\n",
            "    accuracy                           0.65      3577\n",
            "   macro avg       0.60      0.60      0.59      3577\n",
            "weighted avg       0.65      0.65      0.65      3577\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.40      0.29        30\n",
            "           1       0.34      0.26      0.30        65\n",
            "           2       0.30      0.35      0.32        60\n",
            "           3       0.31      0.26      0.29        42\n",
            "           4       0.49      0.44      0.46        50\n",
            "           5       0.55      0.48      0.51       177\n",
            "           6       0.15      0.17      0.16        48\n",
            "           7       0.08      0.05      0.06        41\n",
            "           8       0.37      0.47      0.42        99\n",
            "\n",
            "    accuracy                           0.37       612\n",
            "   macro avg       0.31      0.32      0.31       612\n",
            "weighted avg       0.37      0.37      0.37       612\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.83      0.71       387\n",
            "           1       0.57      0.64      0.60       233\n",
            "           2       0.67      0.66      0.67       444\n",
            "           3       0.75      0.73      0.74       629\n",
            "           4       0.50      0.58      0.54        77\n",
            "           5       0.17      0.09      0.12        55\n",
            "           6       0.77      0.63      0.69       561\n",
            "           7       0.65      0.64      0.65       439\n",
            "           8       0.37      0.35      0.36       173\n",
            "\n",
            "    accuracy                           0.66      2998\n",
            "   macro avg       0.56      0.57      0.56      2998\n",
            "weighted avg       0.66      0.66      0.65      2998\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.44      0.30        39\n",
            "           1       0.28      0.26      0.27        43\n",
            "           2       0.22      0.08      0.12        24\n",
            "           3       0.43      0.43      0.43        54\n",
            "           4       0.37      0.28      0.32        67\n",
            "           5       0.27      0.22      0.24        54\n",
            "           6       0.39      0.60      0.48        25\n",
            "           7       0.70      0.73      0.72       331\n",
            "           8       0.69      0.65      0.67       209\n",
            "\n",
            "    accuracy                           0.56       846\n",
            "   macro avg       0.40      0.41      0.39       846\n",
            "weighted avg       0.56      0.56      0.56       846\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.44      0.45       113\n",
            "           1       0.66      0.65      0.66       735\n",
            "           2       0.59      0.69      0.63       439\n",
            "           3       0.66      0.66      0.66       347\n",
            "           4       0.66      0.63      0.64       302\n",
            "           5       0.74      0.74      0.74       932\n",
            "           6       0.69      0.66      0.67       332\n",
            "           7       0.27      0.17      0.21       121\n",
            "           8       0.49      0.54      0.52       125\n",
            "\n",
            "    accuracy                           0.65      3446\n",
            "   macro avg       0.58      0.58      0.58      3446\n",
            "weighted avg       0.65      0.65      0.65      3446\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.45      0.36        31\n",
            "           1       0.11      0.45      0.17        11\n",
            "           2       0.32      0.32      0.32        74\n",
            "           3       0.30      0.43      0.36        74\n",
            "           4       0.31      0.26      0.28        42\n",
            "           5       0.36      0.43      0.39        69\n",
            "           6       0.34      0.26      0.29        85\n",
            "           7       0.37      0.20      0.26       117\n",
            "           8       0.31      0.23      0.26        70\n",
            "\n",
            "    accuracy                           0.31       573\n",
            "   macro avg       0.30      0.34      0.30       573\n",
            "weighted avg       0.33      0.31      0.31       573\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73       364\n",
            "           1       0.71      0.82      0.76       327\n",
            "           2       0.69      0.70      0.69       326\n",
            "           3       0.67      0.63      0.65       212\n",
            "           4       0.49      0.59      0.54       100\n",
            "           5       0.62      0.62      0.62       201\n",
            "           6       0.77      0.75      0.76       234\n",
            "           7       0.88      0.74      0.80       419\n",
            "           8       0.61      0.68      0.64       272\n",
            "\n",
            "    accuracy                           0.71      2455\n",
            "   macro avg       0.69      0.69      0.69      2455\n",
            "weighted avg       0.72      0.71      0.71      2455\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.32      0.25        38\n",
            "           1       0.18      0.31      0.23        48\n",
            "           2       0.34      0.37      0.35       167\n",
            "           3       0.22      0.28      0.25        87\n",
            "           4       0.05      0.03      0.04        29\n",
            "           5       0.25      0.20      0.22        71\n",
            "           6       0.31      0.26      0.29        95\n",
            "           7       0.26      0.21      0.23       135\n",
            "           8       0.23      0.19      0.21       132\n",
            "\n",
            "    accuracy                           0.26       802\n",
            "   macro avg       0.23      0.24      0.23       802\n",
            "weighted avg       0.26      0.26      0.25       802\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.70      0.65       182\n",
            "           1       0.56      0.64      0.60       249\n",
            "           2       0.50      0.57      0.53       205\n",
            "           3       0.59      0.60      0.59       373\n",
            "           4       0.72      0.67      0.69       330\n",
            "           5       0.54      0.46      0.50       177\n",
            "           6       0.58      0.70      0.63       321\n",
            "           7       0.78      0.71      0.75       623\n",
            "           8       0.65      0.59      0.62       536\n",
            "\n",
            "    accuracy                           0.64      2996\n",
            "   macro avg       0.62      0.63      0.62      2996\n",
            "weighted avg       0.64      0.64      0.64      2996\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.53      0.39        15\n",
            "           1       0.27      0.38      0.32        34\n",
            "           2       0.57      0.24      0.33        34\n",
            "           3       0.27      0.41      0.32        27\n",
            "           4       0.00      0.00      0.00         6\n",
            "           5       0.21      0.25      0.23        16\n",
            "           6       0.00      0.00      0.00        19\n",
            "           7       0.27      0.31      0.29        45\n",
            "           8       0.08      0.04      0.05        28\n",
            "\n",
            "    accuracy                           0.26       224\n",
            "   macro avg       0.22      0.24      0.21       224\n",
            "weighted avg       0.26      0.26      0.24       224\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.51      0.51        80\n",
            "           1       0.66      0.77      0.71       582\n",
            "           2       0.74      0.76      0.75       568\n",
            "           3       0.61      0.64      0.62       291\n",
            "           4       0.58      0.44      0.50       204\n",
            "           5       0.32      0.19      0.24       216\n",
            "           6       0.84      0.80      0.82       387\n",
            "           7       0.32      0.36      0.34       227\n",
            "           8       0.47      0.48      0.48       219\n",
            "\n",
            "    accuracy                           0.62      2774\n",
            "   macro avg       0.56      0.55      0.55      2774\n",
            "weighted avg       0.62      0.62      0.62      2774\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.34      0.35        61\n",
            "           1       0.33      0.48      0.39        58\n",
            "           2       0.24      0.22      0.23        46\n",
            "           3       0.29      0.36      0.32        28\n",
            "           4       0.31      0.29      0.30        55\n",
            "           5       0.90      0.87      0.89       576\n",
            "           6       0.50      0.37      0.43       123\n",
            "           7       0.66      0.68      0.67       336\n",
            "           8       0.31      0.39      0.34        67\n",
            "\n",
            "    accuracy                           0.66      1350\n",
            "   macro avg       0.43      0.45      0.44      1350\n",
            "weighted avg       0.67      0.66      0.66      1350\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79       176\n",
            "           1       0.62      0.72      0.67       108\n",
            "           2       0.78      0.80      0.79       297\n",
            "           3       0.79      0.83      0.81       468\n",
            "           4       0.72      0.67      0.69       143\n",
            "           5       0.38      0.56      0.45         9\n",
            "           6       0.81      0.73      0.77       384\n",
            "           7       0.37      0.28      0.31        40\n",
            "           8       0.73      0.67      0.70       273\n",
            "\n",
            "    accuracy                           0.75      1898\n",
            "   macro avg       0.66      0.68      0.67      1898\n",
            "weighted avg       0.75      0.75      0.75      1898\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31        22\n",
            "           1       0.31      0.31      0.31        48\n",
            "           2       0.25      0.30      0.28        73\n",
            "           3       0.37      0.40      0.39        67\n",
            "           4       0.14      0.38      0.21         8\n",
            "           5       0.35      0.30      0.33        92\n",
            "           6       0.35      0.26      0.30        43\n",
            "           7       0.34      0.32      0.33        73\n",
            "           8       0.31      0.28      0.29       105\n",
            "\n",
            "    accuracy                           0.31       531\n",
            "   macro avg       0.30      0.32      0.30       531\n",
            "weighted avg       0.32      0.31      0.31       531\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.75      0.66       251\n",
            "           1       0.67      0.77      0.71       477\n",
            "           2       0.75      0.75      0.75       431\n",
            "           3       0.43      0.45      0.44       279\n",
            "           4       0.65      0.65      0.65       143\n",
            "           5       0.39      0.29      0.34       177\n",
            "           6       0.64      0.51      0.57       402\n",
            "           7       0.73      0.66      0.69       323\n",
            "           8       0.23      0.24      0.23        72\n",
            "\n",
            "    accuracy                           0.62      2555\n",
            "   macro avg       0.57      0.56      0.56      2555\n",
            "weighted avg       0.62      0.62      0.62      2555\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.40      0.34        25\n",
            "           1       0.28      0.25      0.26        44\n",
            "           2       0.43      0.37      0.40        76\n",
            "           3       0.72      0.76      0.74       253\n",
            "           4       0.26      0.24      0.25        33\n",
            "           5       0.92      0.93      0.93       489\n",
            "           6       0.32      0.29      0.30        86\n",
            "           7       0.34      0.27      0.30        73\n",
            "           8       0.20      0.25      0.22        44\n",
            "\n",
            "    accuracy                           0.68      1123\n",
            "   macro avg       0.42      0.42      0.42      1123\n",
            "weighted avg       0.67      0.68      0.67      1123\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.80      0.75       385\n",
            "           1       0.48      0.57      0.52       305\n",
            "           2       0.44      0.46      0.45       289\n",
            "           3       0.25      0.33      0.28       104\n",
            "           4       0.74      0.69      0.71       163\n",
            "           5       0.28      0.20      0.24       220\n",
            "           6       0.63      0.66      0.64       240\n",
            "           7       0.68      0.63      0.66       754\n",
            "           8       0.36      0.31      0.34       341\n",
            "\n",
            "    accuracy                           0.55      2801\n",
            "   macro avg       0.51      0.52      0.51      2801\n",
            "weighted avg       0.55      0.55      0.55      2801\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.20      0.20        10\n",
            "           1       0.30      0.20      0.24        15\n",
            "           2       0.29      0.50      0.36         4\n",
            "           3       0.79      0.84      0.81       368\n",
            "           4       0.58      0.35      0.44        20\n",
            "           5       0.93      0.95      0.94       441\n",
            "           6       0.67      0.50      0.57         4\n",
            "           7       0.39      0.36      0.38        33\n",
            "           8       0.92      0.87      0.90       441\n",
            "\n",
            "    accuracy                           0.85      1336\n",
            "   macro avg       0.56      0.53      0.54      1336\n",
            "weighted avg       0.85      0.85      0.85      1336\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.58      0.57       208\n",
            "           1       0.67      0.67      0.67       563\n",
            "           2       0.67      0.70      0.68       739\n",
            "           3       0.26      0.37      0.30        99\n",
            "           4       0.61      0.63      0.62       444\n",
            "           5       0.35      0.35      0.35       176\n",
            "           6       0.26      0.22      0.24        95\n",
            "           7       0.76      0.74      0.75       812\n",
            "           8       0.34      0.21      0.26       156\n",
            "\n",
            "    accuracy                           0.62      3292\n",
            "   macro avg       0.50      0.50      0.49      3292\n",
            "weighted avg       0.62      0.62      0.62      3292\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.33      0.27        42\n",
            "           1       0.37      0.39      0.38       155\n",
            "           2       0.22      0.31      0.26        16\n",
            "           3       0.75      0.82      0.78       364\n",
            "           4       0.12      0.12      0.12        16\n",
            "           5       0.64      0.70      0.67       390\n",
            "           6       0.67      0.66      0.66       450\n",
            "           7       0.36      0.30      0.33       168\n",
            "           8       0.83      0.74      0.79       662\n",
            "\n",
            "    accuracy                           0.66      2263\n",
            "   macro avg       0.47      0.49      0.47      2263\n",
            "weighted avg       0.67      0.66      0.66      2263\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.74       160\n",
            "           1       0.76      0.85      0.80       380\n",
            "           2       0.65      0.73      0.69       241\n",
            "           3       0.33      0.33      0.33       129\n",
            "           4       0.79      0.75      0.77       357\n",
            "           5       0.21      0.26      0.24        99\n",
            "           6       0.35      0.30      0.32       121\n",
            "           7       0.22      0.12      0.16       161\n",
            "           8       0.30      0.38      0.33        64\n",
            "\n",
            "    accuracy                           0.60      1712\n",
            "   macro avg       0.49      0.49      0.49      1712\n",
            "weighted avg       0.59      0.60      0.59      1712\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.42      0.41        57\n",
            "           1       0.39      0.58      0.47       103\n",
            "           2       0.33      0.19      0.24        69\n",
            "           3       0.78      0.82      0.80       437\n",
            "           4       0.42      0.28      0.33        36\n",
            "           5       0.48      0.31      0.38        96\n",
            "           6       0.73      0.78      0.76       627\n",
            "           7       0.73      0.69      0.71       301\n",
            "           8       0.66      0.61      0.63       343\n",
            "\n",
            "    accuracy                           0.68      2069\n",
            "   macro avg       0.55      0.52      0.53      2069\n",
            "weighted avg       0.67      0.68      0.67      2069\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       327\n",
            "           1       0.80      0.84      0.82       416\n",
            "           2       0.65      0.77      0.71       242\n",
            "           3       0.23      0.27      0.25        62\n",
            "           4       0.62      0.65      0.63       153\n",
            "           5       0.90      0.81      0.85       525\n",
            "           6       0.53      0.29      0.38        31\n",
            "           7       0.20      0.13      0.16        62\n",
            "           8       0.22      0.06      0.10        31\n",
            "\n",
            "    accuracy                           0.74      1849\n",
            "   macro avg       0.54      0.52      0.52      1849\n",
            "weighted avg       0.73      0.74      0.73      1849\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.39      0.28        28\n",
            "           1       0.36      0.54      0.43        80\n",
            "           2       0.29      0.38      0.33       115\n",
            "           3       0.71      0.84      0.77       560\n",
            "           4       0.28      0.32      0.30        37\n",
            "           5       0.39      0.24      0.30       239\n",
            "           6       0.21      0.12      0.15       112\n",
            "           7       0.65      0.61      0.63       374\n",
            "           8       0.33      0.25      0.28       149\n",
            "\n",
            "    accuracy                           0.54      1694\n",
            "   macro avg       0.38      0.41      0.39      1694\n",
            "weighted avg       0.52      0.54      0.53      1694\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.73      0.71       250\n",
            "           1       0.76      0.81      0.79       437\n",
            "           2       0.63      0.72      0.67       363\n",
            "           3       0.38      0.37      0.38        65\n",
            "           4       0.69      0.71      0.70       351\n",
            "           5       0.55      0.49      0.52       148\n",
            "           6       0.62      0.56      0.59       248\n",
            "           7       0.26      0.17      0.20        90\n",
            "           8       0.85      0.80      0.83       468\n",
            "\n",
            "    accuracy                           0.69      2420\n",
            "   macro avg       0.60      0.60      0.60      2420\n",
            "weighted avg       0.69      0.69      0.69      2420\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.20      0.33         5\n",
            "           1       0.26      0.56      0.36        25\n",
            "           2       0.33      1.00      0.50         1\n",
            "           3       0.88      0.91      0.90       446\n",
            "           4       1.00      0.17      0.29         6\n",
            "           5       0.31      0.42      0.36        66\n",
            "           6       0.50      0.19      0.28        47\n",
            "           7       0.95      0.92      0.94       826\n",
            "           8       0.29      0.22      0.25        36\n",
            "\n",
            "    accuracy                           0.84      1458\n",
            "   macro avg       0.61      0.51      0.47      1458\n",
            "weighted avg       0.86      0.84      0.84      1458\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.66      0.64       558\n",
            "           1       0.62      0.75      0.68       567\n",
            "           2       0.70      0.68      0.69       638\n",
            "           3       0.35      0.43      0.39        87\n",
            "           4       0.60      0.52      0.56       346\n",
            "           5       0.63      0.67      0.65       403\n",
            "           6       0.77      0.65      0.71       485\n",
            "           7       0.40      0.11      0.18        35\n",
            "           8       0.65      0.60      0.62       436\n",
            "\n",
            "    accuracy                           0.64      3555\n",
            "   macro avg       0.59      0.56      0.57      3555\n",
            "weighted avg       0.65      0.64      0.64      3555\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.38      0.32         8\n",
            "           1       0.37      0.35      0.36        31\n",
            "           2       0.15      0.15      0.15        20\n",
            "           3       0.82      0.73      0.77       153\n",
            "           4       0.30      0.60      0.40         5\n",
            "           5       0.35      0.43      0.38        58\n",
            "           6       0.43      0.28      0.34        69\n",
            "           7       0.94      0.94      0.94       664\n",
            "           8       0.30      0.53      0.38        32\n",
            "\n",
            "    accuracy                           0.78      1040\n",
            "   macro avg       0.44      0.49      0.45      1040\n",
            "weighted avg       0.80      0.78      0.79      1040\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.69      0.63       323\n",
            "           1       0.66      0.81      0.73       524\n",
            "           2       0.67      0.69      0.68       400\n",
            "           3       0.20      0.19      0.19        70\n",
            "           4       0.75      0.69      0.72       561\n",
            "           5       0.77      0.67      0.72       278\n",
            "           6       0.71      0.57      0.63       340\n",
            "           7       0.21      0.26      0.23        70\n",
            "           8       0.71      0.62      0.66       372\n",
            "\n",
            "    accuracy                           0.67      2938\n",
            "   macro avg       0.59      0.58      0.58      2938\n",
            "weighted avg       0.67      0.67      0.67      2938\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.45      0.34        33\n",
            "           1       0.20      0.35      0.25        49\n",
            "           2       0.19      0.19      0.19        36\n",
            "           3       0.60      0.62      0.61       223\n",
            "           4       0.12      0.09      0.10        45\n",
            "           5       0.49      0.43      0.46       104\n",
            "           6       0.25      0.40      0.31        42\n",
            "           7       0.96      0.89      0.92       677\n",
            "           8       0.36      0.25      0.30        83\n",
            "\n",
            "    accuracy                           0.67      1292\n",
            "   macro avg       0.38      0.41      0.39      1292\n",
            "weighted avg       0.70      0.67      0.68      1292\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.67      0.62       257\n",
            "           1       0.40      0.57      0.47       223\n",
            "           2       0.73      0.78      0.75       490\n",
            "           3       0.39      0.33      0.36       279\n",
            "           4       0.66      0.68      0.67       233\n",
            "           5       0.42      0.35      0.38       295\n",
            "           6       0.69      0.64      0.66       479\n",
            "           7       0.38      0.36      0.37       234\n",
            "           8       0.66      0.62      0.64       420\n",
            "\n",
            "    accuracy                           0.58      2910\n",
            "   macro avg       0.55      0.55      0.55      2910\n",
            "weighted avg       0.58      0.58      0.57      2910\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.55      0.41        22\n",
            "           1       0.42      0.28      0.33        40\n",
            "           2       0.28      0.27      0.27        26\n",
            "           3       0.81      0.88      0.84       241\n",
            "           4       0.44      0.60      0.50        57\n",
            "           5       0.86      0.85      0.85       331\n",
            "           6       0.21      0.23      0.22        66\n",
            "           7       0.85      0.76      0.80       313\n",
            "           8       0.38      0.31      0.34        54\n",
            "\n",
            "    accuracy                           0.72      1150\n",
            "   macro avg       0.51      0.52      0.51      1150\n",
            "weighted avg       0.73      0.72      0.72      1150\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72       312\n",
            "           1       0.47      0.54      0.50       157\n",
            "           2       0.77      0.78      0.77       562\n",
            "           3       0.33      0.27      0.30        74\n",
            "           4       0.21      0.26      0.23        57\n",
            "           5       0.28      0.28      0.28       116\n",
            "           6       0.70      0.68      0.69       262\n",
            "           7       0.58      0.46      0.52       209\n",
            "           8       0.64      0.62      0.63       235\n",
            "\n",
            "    accuracy                           0.63      1984\n",
            "   macro avg       0.52      0.52      0.52      1984\n",
            "weighted avg       0.63      0.63      0.63      1984\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.35      0.28        17\n",
            "           1       0.70      0.75      0.72       272\n",
            "           2       0.39      0.42      0.40        55\n",
            "           3       0.77      0.85      0.81       418\n",
            "           4       0.53      0.50      0.51        84\n",
            "           5       0.80      0.75      0.77       446\n",
            "           6       0.40      0.34      0.37        47\n",
            "           7       0.71      0.73      0.72       202\n",
            "           8       0.38      0.16      0.23        87\n",
            "\n",
            "    accuracy                           0.70      1628\n",
            "   macro avg       0.54      0.54      0.53      1628\n",
            "weighted avg       0.69      0.70      0.69      1628\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.77      0.73       111\n",
            "           1       0.56      0.65      0.60       299\n",
            "           2       0.57      0.52      0.54       203\n",
            "           3       0.24      0.43      0.31        49\n",
            "           4       0.36      0.27      0.31        33\n",
            "           5       0.35      0.37      0.36       169\n",
            "           6       0.83      0.82      0.83       440\n",
            "           7       0.82      0.72      0.77       332\n",
            "           8       0.75      0.68      0.71       419\n",
            "\n",
            "    accuracy                           0.66      2055\n",
            "   macro avg       0.57      0.58      0.57      2055\n",
            "weighted avg       0.68      0.66      0.67      2055\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.32      0.30        19\n",
            "           1       0.74      0.63      0.68       115\n",
            "           2       0.48      0.50      0.49       124\n",
            "           3       0.82      0.89      0.85       599\n",
            "           4       0.93      0.86      0.89       478\n",
            "           5       0.36      0.41      0.38        81\n",
            "           6       0.36      0.32      0.34       113\n",
            "           7       0.16      0.16      0.16        44\n",
            "           8       0.38      0.33      0.35        63\n",
            "\n",
            "    accuracy                           0.72      1636\n",
            "   macro avg       0.50      0.49      0.49      1636\n",
            "weighted avg       0.72      0.72      0.72      1636\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.71      0.71       276\n",
            "           1       0.36      0.43      0.39       246\n",
            "           2       0.73      0.63      0.68       318\n",
            "           3       0.50      0.43      0.46        30\n",
            "           4       0.17      1.00      0.29         1\n",
            "           5       0.82      0.83      0.83       733\n",
            "           6       0.59      0.54      0.56       203\n",
            "           7       0.72      0.67      0.69       475\n",
            "           8       0.60      0.64      0.62       310\n",
            "\n",
            "    accuracy                           0.68      2592\n",
            "   macro avg       0.57      0.65      0.58      2592\n",
            "weighted avg       0.68      0.68      0.68      2592\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.36      0.29        42\n",
            "           1       0.75      0.86      0.80       166\n",
            "           2       0.38      0.34      0.36       113\n",
            "           3       0.59      0.68      0.63       238\n",
            "           4       0.95      0.84      0.89       245\n",
            "           5       0.38      0.54      0.45       123\n",
            "           6       0.47      0.38      0.42        98\n",
            "           7       0.25      0.12      0.16        42\n",
            "           8       0.47      0.19      0.27        81\n",
            "\n",
            "    accuracy                           0.60      1148\n",
            "   macro avg       0.50      0.48      0.47      1148\n",
            "weighted avg       0.60      0.60      0.59      1148\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.71      0.62       133\n",
            "           1       0.38      0.39      0.39       183\n",
            "           2       0.70      0.70      0.70       351\n",
            "           3       0.31      0.41      0.35       128\n",
            "           4       0.28      0.23      0.25       106\n",
            "           5       0.55      0.57      0.56       261\n",
            "           6       0.68      0.65      0.66       320\n",
            "           7       0.86      0.81      0.84       993\n",
            "           8       0.66      0.64      0.65       351\n",
            "\n",
            "    accuracy                           0.66      2826\n",
            "   macro avg       0.55      0.57      0.56      2826\n",
            "weighted avg       0.67      0.66      0.67      2826\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.32      0.29        31\n",
            "           1       0.66      0.76      0.70       172\n",
            "           2       0.28      0.36      0.32        50\n",
            "           3       0.53      0.60      0.56       121\n",
            "           4       0.66      0.59      0.62       257\n",
            "           5       0.32      0.46      0.37       113\n",
            "           6       0.37      0.30      0.33       108\n",
            "           7       0.33      0.27      0.30        88\n",
            "           8       0.42      0.29      0.34       167\n",
            "\n",
            "    accuracy                           0.49      1107\n",
            "   macro avg       0.43      0.44      0.43      1107\n",
            "weighted avg       0.49      0.49      0.48      1107\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.77      0.74       400\n",
            "           1       0.33      0.39      0.36       145\n",
            "           2       0.80      0.84      0.82       767\n",
            "           3       0.32      0.43      0.37       131\n",
            "           4       0.38      0.25      0.30        24\n",
            "           5       0.69      0.63      0.66       254\n",
            "           6       0.35      0.24      0.28       117\n",
            "           7       0.77      0.68      0.72       393\n",
            "           8       0.41      0.31      0.35        85\n",
            "\n",
            "    accuracy                           0.67      2316\n",
            "   macro avg       0.53      0.50      0.51      2316\n",
            "weighted avg       0.67      0.67      0.67      2316\n",
            "\n",
            "No winning\n",
            "No winning\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "Decesion Tree 1  wins\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Win Result : \n",
            " 10thDecisionTree  :  3  OtherDecisionTree :  1  Draw :  5\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "Win Result : \n",
            " 10thDecisionTree  :  7  OtherDecisionTree :  0  Draw :  2\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Win Result : \n",
            " 10thDecisionTree  :  6  OtherDecisionTree :  0  Draw :  3\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "Decision Tree 10 wins\n",
            "Win Result : \n",
            " 10thDecisionTree  :  5  OtherDecisionTree :  0  Draw :  4\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "Decision Tree 10 wins\n",
            "No winning\n",
            "No winning\n",
            "No winning\n",
            "Win Result : \n",
            " 10thDecisionTree  :  3  OtherDecisionTree :  0  Draw :  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu14Q9TQ4WEJ",
        "colab_type": "text"
      },
      "source": [
        "Please enter the number of games to be played : 100\n",
        "\n",
        "Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 100\n",
        "Attempting to import the generated dataset \n",
        "Finish importing the dataset\n",
        "\n",
        "Maximum accuracy :  0.6877673224978614\n",
        "Maximum depth of decision tree is :  11\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree :  6  Other Decision Tree :  0  Draw :  3\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree :  2  Other Decision Tree :  0  Draw :  7\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree :  5  Other Decision Tree :  0  Draw :  4\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decesion Tree 31  wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree :  3  Other Decision Tree :  1  Draw :  5\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree :  3  Other Decision Tree :  0  Draw :  6\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree :  4  Other Decision Tree :  0  Draw :  5\n",
        "No winning\n",
        "No winning\n",
        "Decesion Tree 61  wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree :  6  Other Decision Tree :  1  Draw :  2\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree :  4  Other Decision Tree :  0  Draw :  5\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree :  7  Other Decision Tree :  0  Draw :  2\n",
        "Decesion Tree 91  wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Win Result :  \n",
        " 10thDecisionTree :  4  Other Decision Tree :  1  Draw :  4\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dJLZEZp4WEJ",
        "colab_type": "text"
      },
      "source": [
        "Please enter the number of games to be played : 10\n",
        "Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 100\n",
        "Attempting to import the generated dataset \n",
        "Finish importing the dataset\n",
        "\n",
        "Maximum accuracy :  0.6877673224978614\n",
        "Maximum depth of decision tree is :  11\n",
        "No winning\n",
        "Decesion Tree 1  wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decesion Tree 1  wins\n",
        "Decision Tree 10 wins\n",
        "Decesion Tree 1  wins\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  3  OtherDecisionTree :  3  Draw :  3\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Decesion Tree 11  wins\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  3  OtherDecisionTree :  1  Draw :  5\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decesion Tree 21  wins\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  7  OtherDecisionTree :  1  Draw :  1\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decesion Tree 31  wins\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  5  OtherDecisionTree :  1  Draw :  3\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Decesion Tree 41  wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  1  OtherDecisionTree :  1  Draw :  7\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  3  OtherDecisionTree :  0  Draw :  6\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  8  OtherDecisionTree :  0  Draw :  1\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decesion Tree 71  wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  4  OtherDecisionTree :  1  Draw :  4\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  4  OtherDecisionTree :  0  Draw :  5\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  6  OtherDecisionTree :  0  Draw :  3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCMIhykT4WEK",
        "colab_type": "text"
      },
      "source": [
        "Please enter the number of games to be played : 10\n",
        "Please enter the number of datasets required to be created. Each dataset is a collection of states of a number of OXO games : 50\n",
        "Attempting to import the generated dataset \n",
        "Finish importing the dataset\n",
        "\n",
        "Maximum accuracy :  0.6877673224978614\n",
        "Maximum depth of decision tree is :  11\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  5  OtherDecisionTree :  0  Draw :  4\n",
        "No winning\n",
        "Decesion Tree 11  wins\n",
        "Decision Tree 10 wins\n",
        "Decesion Tree 11  wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  3  OtherDecisionTree :  2  Draw :  4\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decesion Tree 21  wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  2  OtherDecisionTree :  1  Draw :  6\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Win Result : \n",
        " 10thDecisionTree  :  4  OtherDecisionTree :  0  Draw :  5\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "No winning\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Decision Tree 10 wins\n",
        "No winning\n",
        "Decision Tree 10 wins\n",
        "Win Result : \n",
        " 10thDecisionTree  :  5  OtherDecisionTree :  0  Draw :  4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z400Bmyc4WEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}